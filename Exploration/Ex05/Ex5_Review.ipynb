{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24141bb-9c7c-4b1e-9253-027cd669f010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==4.3.2\n",
      "  Downloading gensim-4.3.2.tar.gz (23.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.3/23.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.12/site-packages (from gensim==4.3.2) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from gensim==4.3.2) (1.15.2)\n",
      "Collecting smart_open>=1.8.1 (from gensim==4.3.2)\n",
      "  Downloading smart_open-7.3.0.post1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart_open>=1.8.1->gensim==4.3.2)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Downloading smart_open-7.3.0.post1-py3-none-any.whl (61 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gensim: filename=gensim-4.3.2-cp312-cp312-linux_x86_64.whl size=24072419 sha256=2ff8de505d9fbe500583257aaf49871f1906dc4ec2d7d4457627471f87f85c5f\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/50/c0/ac/7bb08954bc59d390c848b480a3fc5eec68c14bc77bf334d624\n",
      "Successfully built gensim\n",
      "Installing collected packages: wrapt, smart_open, gensim\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [gensim]2m2/3\u001b[0m [gensim]pen]\n",
      "\u001b[1A\u001b[2KSuccessfully installed gensim-4.3.2 smart_open-7.3.0.post1 wrapt-1.17.2\n",
      "Channels:\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - numpy==1.26.3\n",
      "    - scipy==1.12.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2025.7.14  |       hbd8a1cb_0         152 KB  conda-forge\n",
      "    certifi-2025.7.14          |     pyhd8ed1ab_0         156 KB  conda-forge\n",
      "    libgfortran-ng-15.1.0      |       h69a702a_2          34 KB  conda-forge\n",
      "    numpy-1.26.3               |  py312heda63a1_0         7.1 MB  conda-forge\n",
      "    openssl-3.5.1              |       h7b32b05_0         3.0 MB  conda-forge\n",
      "    scipy-1.12.0               |  py312heda63a1_2        16.3 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        26.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-15.1.0-h69a702a_2 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2025.6.15-hbd8a1cb_0 --> 2025.7.14-hbd8a1cb_0 \n",
      "  certifi                            2025.6.15-pyhd8ed1ab_0 --> 2025.7.14-pyhd8ed1ab_0 \n",
      "  openssl                                  3.5.0-h7b32b05_1 --> 3.5.1-h7b32b05_0 \n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  numpy                               2.2.6-py312h72c5963_0 --> 1.26.3-py312heda63a1_0 \n",
      "  scipy                              1.15.2-py312ha707e6e_0 --> 1.12.0-py312heda63a1_2 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "scipy-1.12.0         | 16.3 MB   |                                       |   0% \n",
      "numpy-1.26.3         | 7.1 MB    |                                       |   0% \u001b[A\n",
      "\n",
      "openssl-3.5.1        | 3.0 MB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "certifi-2025.7.14    | 156 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 152 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "scipy-1.12.0         | 16.3 MB   | 8                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "numpy-1.26.3         | 7.1 MB    | ###2                                  |   9% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 152 KB    | ###############5                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.5.1        | 3.0 MB    | 1                                     |   1% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "certifi-2025.7.14    | 156 KB    | ###7                                  |  10% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 152 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "certifi-2025.7.14    | 156 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgfortran-ng-15.1. | 34 KB     | #################5                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "scipy-1.12.0         | 16.3 MB   | ########3                             |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "numpy-1.26.3         | 7.1 MB    | ##################7                   |  51% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 152 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.5.1        | 3.0 MB    | ############################          |  76% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "certifi-2025.7.14    | 156 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "scipy-1.12.0         | 16.3 MB   | ################3                     |  44% \u001b[A\u001b[A\u001b[A\n",
      "numpy-1.26.3         | 7.1 MB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgfortran-ng-15.1. | 34 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libgfortran-ng-15.1. | 34 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "scipy-1.12.0         | 16.3 MB   | ####################################5 |  99% \u001b[A\u001b[A\n",
      "numpy-1.26.3         | 7.1 MB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "scipy-1.12.0         | 16.3 MB   | ##################################### | 100% \u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p sentiment_classification/data\n",
    "\n",
    "# 실습에 활용할 수 있도록 라이브러리 설치 및 다운그레이드를 수행합니다\n",
    "!pip install gensim==4.3.2\n",
    "!conda install scipy==1.12.0 numpy==1.26.3 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc02b16-9c3d-48e2-b107-8cb14882d56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2. 텍스트 감정분석의 유용성\\n오늘 우리는 딥러닝을 통해 텍스트에 담긴 감성을 분석(Sentimental Analysis)하는 방법을 \\n배워 볼 것입니다. 구체적으로는 IMDB나 네이버 영화 리뷰 텍스트에 담긴 이용자의 감성이 \\n긍정적인지 혹은 부정적인지를 분류(Classification) 할 수 있는 딥러닝 모델을 만들어 볼 \\n것입니다.\\n그런데 딥러닝을 이용한 텍스트 감성분석은 어떤 점에서 유용할까요? \\n이 막연한 질문을 좀 더 세부적인 질문으로 잘게 쪼개면 다음과 같은 질문들로 나눠볼 수\\n있을 것입니다.\\n\\n텍스트 데이터만이 가지고 있는 정보적 특성과 가치는 어떤 것일까요?\\n감성분석 등 텍스트 분류 모델이 다른 데이터 분석 업무에 어떤 점에서 도움을 주나요?\\n텍스트 데이터 분석의 기술적 어려움은 무엇인가요?\\n텍스트 분류 작업을 하는데 딥러닝이 적용되면 어떤 점에서 유리해질까요?\\n\\n이 질문들에 답을 제공하는 유용한 아티클 하나를 소개하겠습니다. \\n이 아티클을 정독하시면서 위 질문들에 대한 답을 찾아서 스스로 정리해 보시기 바랍니다. \\n하지만 정답이 있는 것은 아닙니다.\\n이 아티클을 통해 산업 현장에서 텍스트 분류가 실제로 활용되는 구체적인 사례도 확인할 수 있습니다.\\n\\n동아비즈니스리뷰 감성분석 활용 사례 기고\\nhttps://dbr.donga.com/article/view/1202/article_no/8891/ac/magazine\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "2. 텍스트 감정분석의 유용성\n",
    "오늘 우리는 딥러닝을 통해 텍스트에 담긴 감성을 분석(Sentimental Analysis)하는 방법을 \n",
    "배워 볼 것입니다. 구체적으로는 IMDB나 네이버 영화 리뷰 텍스트에 담긴 이용자의 감성이 \n",
    "긍정적인지 혹은 부정적인지를 분류(Classification) 할 수 있는 딥러닝 모델을 만들어 볼 \n",
    "것입니다.\n",
    "그런데 딥러닝을 이용한 텍스트 감성분석은 어떤 점에서 유용할까요? \n",
    "이 막연한 질문을 좀 더 세부적인 질문으로 잘게 쪼개면 다음과 같은 질문들로 나눠볼 수\n",
    "있을 것입니다.\n",
    "\n",
    "텍스트 데이터만이 가지고 있는 정보적 특성과 가치는 어떤 것일까요?\n",
    "감성분석 등 텍스트 분류 모델이 다른 데이터 분석 업무에 어떤 점에서 도움을 주나요?\n",
    "텍스트 데이터 분석의 기술적 어려움은 무엇인가요?\n",
    "텍스트 분류 작업을 하는데 딥러닝이 적용되면 어떤 점에서 유리해질까요?\n",
    "\n",
    "이 질문들에 답을 제공하는 유용한 아티클 하나를 소개하겠습니다. \n",
    "이 아티클을 정독하시면서 위 질문들에 대한 답을 찾아서 스스로 정리해 보시기 바랍니다. \n",
    "하지만 정답이 있는 것은 아닙니다.\n",
    "이 아티클을 통해 산업 현장에서 텍스트 분류가 실제로 활용되는 구체적인 사례도 확인할 수 있습니다.\n",
    "\n",
    "동아비즈니스리뷰 감성분석 활용 사례 기고\n",
    "https://dbr.donga.com/article/view/1202/article_no/8891/ac/magazine\n",
    "\n",
    "3. 텍스트 데이터의 특징\n",
    "인공지능 모델을 입력과 출력이 정해진 함수라고 생각해 봅시다. 예를 들어 MNIST 숫자 분류기 모델이라면 이미지 파일을 읽어 들인 매트릭스가 입력이 되고, 이미지 파일에 쓰여 있는 실제 숫자 값이 출력이 되는 함수가 될 것입니다.\n",
    "이제 텍스트 문장을 입력으로 받아서 그 의미가 긍정이면 1, 부정이면 0을 출력하는 인공지능 모델을 만든다고 생각해 봅시다. 이 모델을 만들기 위해서는 숫자 분류기를 만들 때는 생각할 필요가 없었던 2가지 문제가 생깁니다.\n",
    "\n",
    "텍스트를 어떻게 숫자 행렬로 표현할 수 있나요?\n",
    "텍스트에는 순서가 중요합니다. 입력 데이터의 순서를 인공지능 모델에 어떻게 반영해야 하나요?\n",
    "위 두 문제를 해결하기 위해, 일반적으로 Encoding 과 Embedding이라는 두 가지 기법을 사용합니다.\n",
    "각각의 방식을 어떻게 수행하며, 어떤 차이를 가지는지 살펴보겠습니다.\n",
    "\n",
    "(1) 텍스트를 숫자로 표현하는 방법\n",
    "인공지능 모델의 입력이 될 수 있는 것은 0과 1의 비트로 표현 가능한 숫자만으로 이루어진 매트릭스일 뿐입니다.\n",
    "아주 단순히, A=0, B=1, ..., Z=25 라고 숫자를 임의로 부여한다고 해봅시다.\n",
    "그러면 의미적으로 A와 B는 1만큼 멀고, A와 Z는 25만큼 멀까요? 그렇지 않습니다. 텍스트의 중요한 특징은 그 자체로는 기호일 뿐이며, 텍스트가 내포하는 의미를 기호가 직접 내포하지 않는다는 점입니다.\n",
    "\n",
    "하지만 우리는 우선 단어 사전을 만들어 볼 수는 있습니다. 우리가 사용하는 국어, 영어 사전에는 단어와 그 의미 설명이 짝지어져 있습니다.\n",
    "우리가 하려는 것은 단어와 그 단어의 의미를 나타내는 벡터를 짝지어 보려고 하는 것입니다. 그런데 그 벡터는 어디서 가져올까요? 그렇습니다. 우리는 딥러닝을 통해 그 벡터를 만들어 낼 수 있습니다.\n",
    "\n",
    "아래와 같이 단 3개의 짧은 문장으로 이루어진 텍스트 데이터를 처리하는 간단한 예제를 생각해 보겠습니다.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58cde026-24b5-4f92-9e33-f6fd9398e015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2311fc4a-2a61-4f57-bdf6-4ec41388af83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다.\n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다.\n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf822048-6882-4da2-9f03-6e7efe7fb418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "# 단어 10개짜리 작은 딕셔너리가 만들어졌습니다. 하지만 우리가 가진 텍스트 데이터를 \n",
    "# 숫자로 바꿔 보려고 하는데, 텍스트를 숫자로 바꾸려면 위의 딕셔너리가 \n",
    "# {텍스트:인덱스} 구조여야 합니다.\n",
    "\n",
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c79ff41-3138-48b5-aca5-99cd0961ab64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# 이 딕셔너리는 단어를 주면 그 단어의 인덱스를 반환하는 방식으로 사용할 수 있습니다.\n",
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f06491c2-2870-4c25-be03-9424fb2210b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 이제 우리가 가진 텍스트 데이터를 숫자로 바꿔 표현해 봅시다.\n",
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다.\n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e008f852-70ec-4ac2-97a5-bff9f0f83931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nget_encoded_sentence 함수를 통해 아래와 같이 매핑된 것이 확인되시나요?\\n\\n<BOS> -> 1\\ni -> 3\\neat -> 6\\nlunch -> 7\\n이렇게 텍스트 혹은 범주형 데이터를 정수에 대응하는 방법을 ‘정수 인코딩’ 이라고 합니다. 인코딩은 이 외에도 원-핫 인코딩, 멀티-핫 인코딩 등이 있습니다.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "get_encoded_sentence 함수를 통해 아래와 같이 매핑된 것이 확인되시나요?\n",
    "\n",
    "<BOS> -> 1\n",
    "i -> 3\n",
    "eat -> 6\n",
    "lunch -> 7\n",
    "이렇게 텍스트 혹은 범주형 데이터를 정수에 대응하는 방법을 ‘정수 인코딩’ 이라고 합니다. \n",
    "인코딩은 이 외에도 원-핫 인코딩, 멀티-핫 인코딩 등이 있습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de06c864-b2d0-4b8b-830b-94b342b1447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다.\n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다.\n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45cdd5e9-6a81-4071-8dd8-1ce44609c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 반대로, encode된 벡터를 decode하여 다시 원래 텍스트 데이터로 복구할 수도 있습니다.\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다.\n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f58fdc-859f-4cde-8253-9a470e6eee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "여기서 정의된 함수들은 이후 스텝들에서 반복해서 활용됩니다.\n",
    "\n",
    "(2) Embedding 레이어의 등장\n",
    "텍스트가 숫자로 변환되어 인공지능 모델의 입력으로 사용될 수 있게 되었지만, \n",
    "이것으로 충분하지는 않습니다. 'i feel hungry'가 1, 3, 4, 5 로 변환되었지만 \n",
    "이 벡터는 텍스트에 담긴 언어의 의미와 대응되는 벡터가 아니라 임의로 부여된 \n",
    "단어의 순서에 불과합니다. 우리가 하려는 것은 단어와 그 단어의 의미를 나타내는 \n",
    "벡터를 짝짓는 것이었습니다. 그래서 단어의 의미를 나타내는 벡터를 훈련 가능한 \n",
    "파라미터로 놓고 이를 딥러닝을 통해 학습해서 최적화하게 됩니다. \n",
    "Tensorflow, Pytorch 등의 딥러닝 프레임워크들은 이러한 의미 벡터 파라미터를 \n",
    "구현한 Embedding 레이어를 제공합니다.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "임베딩(Embedding)이란?\n",
    "자연어 처리(Natural Language Processing)분야에서 임베딩(Embedding)은 사람이 쓰는 \n",
    "자연어를 기계가 이해할 수 있는 숫자형태인 vector로 바꾼 결과 혹은 그 일련의 과정 \n",
    "전체를 의미한다. 가장 간단한 형태의 임베딩은 단어의 빈도를 그대로 벡터로 사용하는 것이다.\n",
    "임베딩을 통해 할수있는 것은 단어나 문장 사이의 코사인 유사도가 가장 높은 단어를 \n",
    "구하는 등의 계산, 단어들 사이의 의미/문법적 정보 도출 벡터 간 연산으로 단어 사이 \n",
    "문법적 관계 도출, 전이 학습(transfer learning)\n",
    "임베딩은 다른 딥러닝 모델의 입력값으로 자주 쓰이고, 품질 좋은 임베딩을 쓸수록 모델의 성능이\n",
    "좋아집니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b2ac5e8-7bca-49b0-9731-363252eea737",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다.\u001b[39;00m\n\u001b[32m     14\u001b[39m raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype=\u001b[33m'\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m raw_inputs_tensor = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m output = embedding(raw_inputs_tensor)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "\u001b[31mTypeError\u001b[39m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=word_vector_dim, padding_idx=0)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다.\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "raw_inputs_tensor = torch.tensor(raw_inputs, dtype=torch.long)\n",
    "output = embedding(raw_inputs_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0324c3e3-4368-4deb-b440-9896b593df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "실행해 보니 에러가 발생합니다. 왜 그럴까요?\n",
    "\n",
    "주의해야 할 점이 있습니다. Embedding 레이어의 인풋이 되는 문장 벡터는 그 길이가 일정해야 합니다. raw_inputs의 3개 벡터의 길이는 각각 4, 4, 5입니다.\n",
    "Pytorch에서는 torch.nn.utils.rnn.pad_sequence라는 편리한 함수를 통해 문장 벡터 뒤에 패딩(<PAD>)을 추가하여 길이를 일정하게 맞춰주는 기능을 제공합니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc46d2bc-c753-4bcd-9b22-ea0110c0519c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3, 4, 5, 0],\n",
      "        [1, 3, 6, 7, 0],\n",
      "        [1, 8, 3, 4, 9]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "raw_inputs = [torch.tensor(sentence, dtype=torch.long) for sentence in raw_inputs]\n",
    "raw_inputs = torch.nn.utils.rnn.pad_sequence(raw_inputs, batch_first=True, padding_value=word_to_index['<PAD>'])\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07322ac-37c6-40c3-bc74-fe6e143bb6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "짧은 문장 뒤쪽이 0으로 채워지는 것을 확인할 수 있습니다. <PAD> 가 0에 매핑되어 있다는 걸 기억하세요.\n",
    "\n",
    "그러면 위에 시도했던 output = embedding(raw_inputs)을 다시 시도해 봅시다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "428c4818-284e-4ab6-86c3-7cc060488363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9413, -0.4875, -0.0331,  0.2379],\n",
      "         [ 1.4724, -0.2652,  0.2035, -0.0043],\n",
      "         [ 1.9105,  0.4566, -1.1188,  0.6647],\n",
      "         [ 2.8405, -1.3145, -0.9470, -0.3501],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.9413, -0.4875, -0.0331,  0.2379],\n",
      "         [ 1.4724, -0.2652,  0.2035, -0.0043],\n",
      "         [ 0.5827,  0.4917,  0.0386, -0.1711],\n",
      "         [ 1.2814, -1.2754,  1.0766, -0.1017],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.9413, -0.4875, -0.0331,  0.2379],\n",
      "         [ 2.2748, -0.1622, -1.2790, -0.7899],\n",
      "         [ 1.4724, -0.2652,  0.2035, -0.0043],\n",
      "         [ 1.9105,  0.4566, -1.1188,  0.6647],\n",
      "         [-2.4637,  1.2624, -0.0161,  0.0233]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)   # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4   # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, word_vector_dim, padding_idx=word_to_index['<PAD>'])\n",
    "\n",
    "# nn.Embedding를 통해 word vector를 모두 일정 길이로 맞춰주어야\n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요.\n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "maxlen = 5\n",
    "padded_sentences = [sentence + [word_to_index['<PAD>']] * (maxlen - len(sentence)) if len(sentence) < maxlen else sentence[:maxlen] for sentence in encoded_sentences]\n",
    "\n",
    "raw_inputs = torch.tensor(padded_sentences, dtype=torch.long)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001c08a-23fc-46ac-b60c-7f861b20463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4. 시퀀스 데이터를 다루는 RNN\n",
    "텍스트 데이터를 다루는 데 주로 사용되는 딥러닝 모델은 바로 Recurrent Neural Network(RNN)입니다. RNN은 시퀀스(Sequence) 형태의 데이터를 처리하기에 최적인 모델로 알려져 있습니다.\n",
    "\n",
    "텍스트 데이터도 시퀀스 데이터라는 관점으로 해석할 수 있습니다만, 시퀀스 데이터의 정의에 \n",
    "가장 잘 어울리는 것은 음성 데이터가 아닐까 합니다. 시퀀스 데이터란 바로 입력이 시간 축을 \n",
    "따라 발생하는 데이터입니다. 예를 들어 이전 스텝의 'i feel hungry'라는 문장을 누군가가 \n",
    "초당 한 단어씩, 3초에 걸쳐 이 문장을 발음했다고 합시다.\n",
    "\n",
    "at time=0s : 듣는이의 귀에 들어온 input='i'\n",
    "at time=1s : 듣는이의 귀에 들어온 input='feel'\n",
    "at time=2s : 듣는이의 귀에 들어온 input='hungry'\n",
    "time=1s인 시점에서 입력으로 받은 문장은 'i feel' 까지입니다. 그다음에 'hungry'가 올지, \n",
    "'happy'가 올지 알 수 없는 상황입니다. RNN은 그런 상황을 묘사하기에 가장 적당한 모델 구조를\n",
    "가지고 있습니다. 왜냐하면 RNN은 시간의 흐름에 따라 새롭게 들어오는 입력에 따라 변하는 \n",
    "현재 상태를 묘사하는 state machine으로 설계되었기 때문입니다.\n",
    "\n",
    "State가 무엇인지 이해를 돕기 위해 다음 그림을 보면서 질문에 대답해 봅시다.\n",
    "\n",
    "https://www.slideshare.net/xguru/ss-16106464\n",
    "\n",
    "[State가 유지된다는 것의 의미]\n",
    "\n",
    "다음 동영상을 통해 RNN의 기본 개념과 설계 구조를 좀 더 구체적으로 확인해 본 후 다음 \n",
    "질문에 대답해 봅시다.\n",
    "\n",
    "김성훈 교수의 모두의 딥러닝 강좌 12강.RNN\n",
    "https://www.youtube.com/watch?v=-SHPG_KMUkQ\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b0b2763-fd20-4277-9214-978066617b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1(\n",
      "  (embedding): Embedding(10, 4)\n",
      "  (lstm): LSTM(4, 8, batch_first=True)\n",
      "  (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 그러면 RNN 모델을 사용하여 이전 스텝의 텍스트 데이터를 처리하는 예제 코드를 구현해 보겠습니다.\n",
    "class Model_1(nn.Module):\n",
    "    def __init__(self, vocab_size, word_vector_dim):\n",
    "        super(Model_1, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, word_vector_dim)\n",
    "        self.lstm = nn.LSTM(word_vector_dim, 8, batch_first=True)   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "        self.fc1 = nn.Linear(8, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(8, 1)    # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        x = h_n[-1]\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "vocab_size = 10   # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다.\n",
    "model = Model_1(vocab_size, word_vector_dim)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048638c2-2249-4159-b4d3-dfb8e645ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 자료형과 RNN에 대해 조금더 쉽게 이해하고 싶다면 아래 링크(24분~55분)를 참고해주세요! \n",
    "# 시퀀스 자료형과 RNN   https://www.youtube.com/watch?v=mG6N0ut9dog&t=1447s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb6648-1aee-4f64-b75e-901e902d599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5. 꼭 RNN이어야 할까?\n",
    "텍스트를 처리하기 위해 RNN이 아니라 1-D Convolution Neural Network(1-D CNN)를 사용할 \n",
    "수도 있습니다.\n",
    "우리는 이미지 분류기를 구현하면서 2-D CNN을 이미 사용해 본 바 있습니다. 이미지는 시퀀스\n",
    "데이터가 아닙니다. \n",
    "이미지 분류기 모델에는 이미지 전체가 한꺼번에 입력으로 사용됩니다.\n",
    "그러므로 1-D CNN은 문장 전체를 한꺼번에 한 방향으로 길이 7짜리 필터로 스캐닝 하면서 \n",
    "7단어 이내에서 발견되는 특징을 추출하여 그것으로 문장을 분류하는 방식으로 사용됩니다.\n",
    "이 방식도 텍스트를 처리하는 데 RNN 못지않은 효율을 보여줍니다.\n",
    "그리고 CNN 계열은 RNN 계열보다 병렬처리가 효율적이기 때문에 학습 속도도 훨씬 빠르게 \n",
    "진행된다는 장점이 있습니다.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "253c9c9b-2d06-4fb7-8781-c14cffbcfcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2(\n",
      "  (embedding): Embedding(10, 4)\n",
      "  (conv1): Conv1d(4, 16, kernel_size=(7,), stride=(1,))\n",
      "  (conv2): Conv1d(16, 16, kernel_size=(7,), stride=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
      "  (global_max_pooling): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc1): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Model_2(nn.Module):\n",
    "    def __init__(self, vocab_size, word_vector_dim):\n",
    "        super(Model_2, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, word_vector_dim)\n",
    "        self.conv1 = nn.Conv1d(word_vector_dim, 16, kernel_size=7)\n",
    "        self.conv2 = nn.Conv1d(16, 16, kernel_size=7)\n",
    "        self.pool = nn.MaxPool1d(5)\n",
    "        self.global_max_pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Linear(16, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(8, 1)    # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.global_max_pooling(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "vocab_size = 10    # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다.\n",
    "model = Model_2(vocab_size, word_vector_dim)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810875b-452d-44a6-9adb-84b72dad9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "아주 간단히는 GlobalMaxPooling1D() 레이어 하나만 사용하는 방법도 생각해 볼 수 있습니다. \n",
    "이 방식은 전체 문장 중에서 단 하나의 가장 중요한 단어만 피처로 추출하여 그것으로 문장의 \n",
    "긍정/부정을 평가하는 방식이라고 생각할 수 있는데, 의외로 성능이 잘 나올 수도 있습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "841087f6-44c6-4214-8c7c-3849fdf449f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3(\n",
      "  (embedding): Embedding(10, 4)\n",
      "  (global_max_pooling): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Model_3(nn.Module):\n",
    "    def __init__(self, vocab_size, word_vector_dim):\n",
    "        super(Model_3, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, word_vector_dim)\n",
    "        self.global_max_pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Linear(word_vector_dim, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(8, 1)    # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.global_max_pooling(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "vocab_size = 10   # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다.\n",
    "model = Model_3(vocab_size, word_vector_dim)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47141b91-9dae-4c37-9c9d-802868d1df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "이 외에도 1-D CNN과 RNN 레이어를 섞어 쓴다거나, FFN(FeedForward Network) 레이어만으로 \n",
    "구성하거나, 혹은 최근 각광받고 있는 Transformer 레이어를 쓰는 등 매우 다양한 시도를 \n",
    "해볼 수 있습니다. 조금더 깊게 알고 싶다면 여기를 참고 하세요\n",
    "https://wikidocs.net/80437\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede71ff-023c-4ea0-be06-5374eb451577",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6. IMDB 영화리뷰 감성분석\n",
    "(1) IMDB 데이터셋 분석\n",
    "이제 본격적으로 IMDb 영화리뷰 감성분석 태스크에 도전해 보겠습니다. \n",
    "IMDb Large Movie Dataset은 50000개의 영어로 작성된 영화 리뷰 텍스트로 구성되어 있으며, \n",
    "긍정은 1, 부정은 0의 라벨이 달려 있습니다. 2011년 Learning Word Vectors for Sentiment A\n",
    "nalysis 논문에서 이 데이터셋을 소개하였습니다.\n",
    "\n",
    "50000개의 리뷰 중 절반인 25000개가 훈련용 데이터, 나머지 25000개를 테스트용 데이터로 \n",
    "사용하도록 지정되어 있습니다. 이 데이터셋은 tensorflow Keras 데이터셋 안에 포함되어 \n",
    "있어서 손쉽게 다운로드하여 사용할 수 있습니다.\n",
    "이후 스텝의 IMDb 데이터셋 처리 코드 중 일부는 Tensorflow 튜토리얼에 언급된 데이터 전처리 \n",
    "로직을 참고하였음을 밝힙니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfe4bf5b-e25e-40c5-b4e8-c6beb5a11587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/home/jovyan/work/sentiment_classification/data': File exists\n"
     ]
    }
   ],
   "source": [
    "!ln -s /home/jovyan/data /home/jovyan/work/sentiment_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ffeab3c-e4cf-4b56-a116-ba9c1252c3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "# 원본 IMDb 데이터셋 다운로드\n",
    "# import tensorflow as tf\n",
    "# imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# 이번 실습에서는 미리 다운로드된 데이터셋을 불러와 활용하겠습니다\n",
    "data_dir = os.path.join(os.getenv('HOME') + '/work/sentiment_classification/data/')\n",
    "\n",
    "x_train = np.load(data_dir + 'imdb_x_train.npy', allow_pickle=True)\n",
    "y_train = np.load(data_dir + 'imdb_y_train.npy', allow_pickle=True)\n",
    "x_test = np.load(data_dir + 'imdb_x_test.npy', allow_pickle=True)\n",
    "y_test = np.load(data_dir + 'imdb_y_test.npy', allow_pickle=True)\n",
    "print(f\"훈련 샘플 개수: {len(x_train)}, 테스트 개수: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7965dfd-5090-49df-a3fd-2e0e2a36ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "imdb.load_data() 호출 시 단어사전에 등재할 단어의 개수(num_words)를 10000으로 지정하면,\n",
    "그 개수만큼의 word_to_index 딕셔너리까지 생성된 형태로 데이터셋이 생성됩니다.\n",
    "\n",
    "다운로드한 데이터 실제 예시를 확인해 보겠습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afbd311d-584b-49e1-9028-e0169f31edee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507b7d5-3c18-4d00-afd1-d5cd8b33f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "텍스트 데이터가 아니라 이미 숫자로 encode된 텍스트 데이터를 다운로드했음을 확인할 \n",
    "수 있습니다.\n",
    "이미 텍스트가 encode되었으므로 IMDb 데이터셋에는 encode에 사용한 딕셔너리까지\n",
    "함께 제공합니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddc1d592-f0ff-4ddc-ba7b-bbdd61f30bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# word_to_index = imdb.get_word_index()\n",
    "word_to_index = np.load(data_dir + 'imdb_word_to_index.pickle', allow_pickle=True)\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다.\n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f61698-1655-4531-bb49-8ed8443e757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "여기서 주의할 점이 있습니다. IMDb 데이터셋의 텍스트 인코딩을 위한 word_to_index, \n",
    "index_to_word는 보정이 필요한데요.\n",
    "\n",
    "예를 들어 다음 코드를 실행시켜보면 보정이 되지 않은 상태라 문장이 이상함을 확인하실 \n",
    "겁니다. (뒤에 보정 후 다시 확인해볼 예정이에요.😊)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1c2a04d-c0ed-4d56-b60c-bb825f5e817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "# 보정 전 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f498612b-d2db-480f-acf8-0c6cf25432e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "그럼 매핑 보정 작업을 해보겠습니다. 아래 내용은 Tensorflow 튜토리얼의 가이드를 \n",
    "반영하여 작성하였습니다.\n",
    "word_to_index는 IMDb 텍스트 데이터셋의 단어 출현 빈도 기준으로 내림차수 \n",
    "정렬되어 있습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4949424b-0b87-4d2d-9cf9-9f586140394a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n",
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.\n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다.\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다.\n",
    "print(word_to_index['the'])  # 4 이 출력됩니다.\n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다.\n",
    "\n",
    "# 보정 후 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774be7c-0012-4271-ae75-beddd0f92abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "다운로드한 데이터셋이 확인되었습니다. 보정 후 x_train[0] 데이터도 자연스러운 \n",
    "문장으로 바뀌었습니다.\n",
    "\n",
    "마지막으로, encode된 텍스트가 정상적으로 decode 되는지 확인해 보겠습니다.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4a8ae00-2a51-4a23-a58f-1b2b4d787631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315490f-f7aa-4f40-a714-1c5c252cd037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "decode 한 문장과 라벨을 비교하여 일치하는지 확인해 주세요.\n",
    "\n",
    "pad_sequences를 통해 데이터셋 상의 문장의 길이를 통일하는 것을 잊어서는 안됩니다.\n",
    "문장 최대 길이 maxlen의 값 설정도 전체 모델 성능에 영향을 미치게 됩니다. \n",
    "이 길이도 적절한 값을 찾기 위해서는 전체 데이터셋의 분포를 확인해 보는 것이 좋습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9d703e0-501e-43f3-ab78-176f7da41092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다.\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a075d60c-f935-4456-a676-74de9295a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "위의 경우에는 maxlen=580이 됩니다.\n",
    "또 한 가지 유의해야 하는 것은 padding 방식을 문장 뒤쪽('post')과 앞쪽('pre') 중 어느 쪽으로 하느냐에 따라 RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다는 점입니다.\n",
    "두 가지 방식을 한 번씩 다 적용해서 RNN을 학습시켜 보면서 그 결과를 비교해 보시기 바랍니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de64f257-9e34-4d8e-b3bf-ce8f646603c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25000, 580])\n"
     ]
    }
   ],
   "source": [
    "def pad_sequences(data, maxlen):\n",
    "    padded_data = []\n",
    "    for sentence in data:\n",
    "        if len(sentence) < maxlen:\n",
    "            sentence = sentence + [0] * (maxlen - len(sentence))\n",
    "        else:\n",
    "            sentence = sentence[:maxlen]\n",
    "        padded_data.append(sentence)\n",
    "    return np.array(padded_data)\n",
    "\n",
    "x_train_padded = pad_sequences(x_train, maxlen)\n",
    "x_test_padded = pad_sequences(x_test, maxlen)\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train_padded, dtype=torch.long)\n",
    "x_test_tensor = torch.tensor(x_test_padded, dtype=torch.long)\n",
    "\n",
    "print(x_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791bc38-7434-4ad4-9bcf-59b69e8752d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(2) 딥러닝 모델 설계와 훈련\n",
    "RNN 모델을 직접 설계해 보겠습니다. 이전 스텝의 실습 내용을 참고해 주세요.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94528430-5041-462f-bff4-9bcc9a94460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentModel(\n",
      "  (embedding): Embedding(10000, 16)\n",
      "  (lstm): LSTM(16, 8, batch_first=True)\n",
      "  (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, vocab_size, word_vector_dim):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, word_vector_dim)\n",
    "        self.lstm = nn.LSTM(word_vector_dim, 8, batch_first=True)\n",
    "        self.fc1 = nn.Linear(8, 8)\n",
    "        self.fc2 = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = SentimentModel(vocab_size, word_vector_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9848a57-afc4-4cff-9f4d-aece908589e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(참고)우리가 사용할 수 있는 모델에는 RNN만 있는 것이 아닙니다. \n",
    "이전 스텝에서 구현해 본 다양한 모델들이 전부 사용 가능합니다.\n",
    "\n",
    "model 훈련 전에, 훈련용 데이터셋 25000건 중 10000건을 분리하여 검증셋(validation set)\n",
    "으로 사용하도록 합니다. 적절한 validation 데이터는 몇 개가 좋을지 고민해 봅시다.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74b5f7de-3bfe-4769-ac10-b2a3143607f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15000, 580])\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train_tensor[:10000]\n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train_tensor[10000:]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043febe-91b0-4f9e-bb2d-c3ef59fc103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 학습을 시작해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24660fee-e1de-43a8-a488-821faf101206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_198/1424571675.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  partial_x_train_tensor = torch.tensor(partial_x_train, dtype=torch.long)\n",
      "/tmp/ipykernel_198/1424571675.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_val_tensor = torch.tensor(x_val, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Train Loss: 0.6932, Train Accuracy: 0.5053 - Validation Loss: 0.6933, Validation Accuracy: 0.4994\n",
      "Epoch 2/30 - Train Loss: 0.6931, Train Accuracy: 0.5086 - Validation Loss: 0.6932, Validation Accuracy: 0.5016\n",
      "Epoch 3/30 - Train Loss: 0.6930, Train Accuracy: 0.5089 - Validation Loss: 0.6933, Validation Accuracy: 0.5016\n",
      "Epoch 4/30 - Train Loss: 0.6929, Train Accuracy: 0.5096 - Validation Loss: 0.6932, Validation Accuracy: 0.5012\n",
      "Epoch 5/30 - Train Loss: 0.6929, Train Accuracy: 0.5099 - Validation Loss: 0.6932, Validation Accuracy: 0.5013\n",
      "Epoch 6/30 - Train Loss: 0.6927, Train Accuracy: 0.5099 - Validation Loss: 0.6931, Validation Accuracy: 0.5016\n",
      "Epoch 7/30 - Train Loss: 0.6927, Train Accuracy: 0.5045 - Validation Loss: 0.6932, Validation Accuracy: 0.5013\n",
      "Epoch 8/30 - Train Loss: 0.6925, Train Accuracy: 0.5105 - Validation Loss: 0.6932, Validation Accuracy: 0.5015\n",
      "Epoch 9/30 - Train Loss: 0.6922, Train Accuracy: 0.5101 - Validation Loss: 0.6932, Validation Accuracy: 0.5011\n",
      "Epoch 10/30 - Train Loss: 0.6921, Train Accuracy: 0.5101 - Validation Loss: 0.6932, Validation Accuracy: 0.5011\n",
      "Epoch 11/30 - Train Loss: 0.6917, Train Accuracy: 0.5108 - Validation Loss: 0.6933, Validation Accuracy: 0.5013\n",
      "Epoch 12/30 - Train Loss: 0.6915, Train Accuracy: 0.5109 - Validation Loss: 0.6933, Validation Accuracy: 0.5011\n",
      "Epoch 13/30 - Train Loss: 0.6913, Train Accuracy: 0.5115 - Validation Loss: 0.6934, Validation Accuracy: 0.5013\n",
      "Epoch 14/30 - Train Loss: 0.6906, Train Accuracy: 0.5091 - Validation Loss: 0.6937, Validation Accuracy: 0.5014\n",
      "Epoch 15/30 - Train Loss: 0.6901, Train Accuracy: 0.5127 - Validation Loss: 0.6939, Validation Accuracy: 0.5012\n",
      "Epoch 16/30 - Train Loss: 0.6894, Train Accuracy: 0.5134 - Validation Loss: 0.6940, Validation Accuracy: 0.5011\n",
      "Epoch 17/30 - Train Loss: 0.6884, Train Accuracy: 0.5155 - Validation Loss: 0.6943, Validation Accuracy: 0.5007\n",
      "Epoch 18/30 - Train Loss: 0.6871, Train Accuracy: 0.5157 - Validation Loss: 0.6947, Validation Accuracy: 0.4999\n",
      "Epoch 19/30 - Train Loss: 0.6855, Train Accuracy: 0.5175 - Validation Loss: 0.6950, Validation Accuracy: 0.5001\n",
      "Epoch 20/30 - Train Loss: 0.6841, Train Accuracy: 0.5195 - Validation Loss: 0.6970, Validation Accuracy: 0.4998\n",
      "Epoch 21/30 - Train Loss: 0.6825, Train Accuracy: 0.5213 - Validation Loss: 0.6975, Validation Accuracy: 0.4997\n",
      "Epoch 22/30 - Train Loss: 0.6807, Train Accuracy: 0.5226 - Validation Loss: 0.7021, Validation Accuracy: 0.4994\n",
      "Epoch 23/30 - Train Loss: 0.6793, Train Accuracy: 0.5211 - Validation Loss: 0.7045, Validation Accuracy: 0.4993\n",
      "Epoch 24/30 - Train Loss: 0.6771, Train Accuracy: 0.5235 - Validation Loss: 0.7044, Validation Accuracy: 0.5000\n",
      "Epoch 25/30 - Train Loss: 0.6754, Train Accuracy: 0.5279 - Validation Loss: 0.7115, Validation Accuracy: 0.5004\n",
      "Epoch 26/30 - Train Loss: 0.6742, Train Accuracy: 0.5289 - Validation Loss: 0.7119, Validation Accuracy: 0.5009\n",
      "Epoch 27/30 - Train Loss: 0.6728, Train Accuracy: 0.5301 - Validation Loss: 0.7128, Validation Accuracy: 0.5051\n",
      "Epoch 28/30 - Train Loss: 0.6717, Train Accuracy: 0.5240 - Validation Loss: 0.7216, Validation Accuracy: 0.5008\n",
      "Epoch 29/30 - Train Loss: 0.6700, Train Accuracy: 0.5314 - Validation Loss: 0.7193, Validation Accuracy: 0.5009\n",
      "Epoch 30/30 - Train Loss: 0.6685, Train Accuracy: 0.5317 - Validation Loss: 0.7239, Validation Accuracy: 0.5014\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "partial_x_train_tensor = torch.tensor(partial_x_train, dtype=torch.long)\n",
    "partial_y_train_tensor = torch.tensor(partial_y_train, dtype=torch.float)\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float)\n",
    "\n",
    "train_dataset = TensorDataset(partial_x_train_tensor, partial_y_train_tensor)\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "epochs = 30   # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다.\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        predicted = (outputs.squeeze() > 0.5).float()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accs.append(correct / total)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs.squeeze(), labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            predicted = (outputs.squeeze() > 0.5).float()\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accs.append(val_correct / val_total)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "          f\"Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accs[-1]:.4f} - \"\n",
    "          f\"Validation Loss: {val_losses[-1]:.4f}, Validation Accuracy: {val_accs[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5a15d-0e88-4086-a0c1-f0a5578c772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습이 끝난 모델을 테스트셋으로 평가해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6416c-e6a5-4705-95e4-edce40dbef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(x_test_tensor, torch.tensor(y_test, dtype=torch.float32))\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.squeeze(), labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        predicted = (outputs.squeeze() > 0.5).float()\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "print(f\"Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {test_correct / test_total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0013b1-2b7a-4f39-9d93-5e9b4f1ea143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model.fit() 과정 중의 train/validation loss, accuracy 등이 매 epoch마다 history \n",
    "변수에 저장되어 있습니다.\n",
    "이 데이터를 그래프로 그려 보면, 수행했던 딥러닝 학습이 잘 진행되었는지, \n",
    "오버피팅 혹은 언더피팅하지 않았는지, 성능을 개선할 수 있는 다양한 아이디어를 \n",
    "얻을 수 있는 좋은 자료가 됩니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d839791-f815-4871-8648-1efd96da8758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_range = range(1, epochs + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs_range, train_losses, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs_range, val_losses, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc605c0-3899-454a-99d6-2d49976b9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training and validation loss를 그려 보면, 몇 epoch까지의 트레이닝이 적절한지 \n",
    "최적점을 추정해 볼 수 있습니다. validation loss의 그래프가 train loss와의\n",
    "이격이 발생하게 되면 더 이상의 트레이닝은 무의미해지게 마련입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "300ceed8-c6f6-4bec-bc83-4850873cd1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs_range, train_accs, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs_range, val_accs, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4241791-760f-477c-9d41-7269dacdbb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "마찬가지로 Training and validation accuracy를 그려 보아도 유사한 인사이트를 얻을 수 있습니다.\n",
    "\n",
    "(3) Word2Vec의 적용\n",
    "이전 스텝에서 라벨링 비용이 많이 드는 머신러닝 기반 감성분석의 비용을 절감하면서 \n",
    "정확도를 크게 향상시킬 수 있는 자연어 처리 기법으로 단어의 특성을 저차원 벡터 값으로 \n",
    "표현할 수 있는 워드 임베딩(word embedding) 기법이 있다는 언급을 한 바 있습니다.\n",
    "\n",
    "우리는 이미 이전 스텝에서 워드 임베딩을 사용했습니다. 사용했던 model의 첫 번째 \n",
    "레이어는 바로 Embedding 레이어였습니다. 이 레이어는 우리가 가진 사전의 단어 개수 \n",
    "X 워드 벡터 사이즈만큼의 크기를 가진 학습 파라미터였습니다. 만약 우리의 감성 분류 \n",
    "모델이 학습이 잘 되었다면, Embedding 레이어에 학습된 우리의 워드 벡터들도 의미 \n",
    "공간상에 유의미한 형태로 학습되었을 것입니다. 한번 확인해 봅시다.\n",
    "\n",
    "이번 스텝부터 워드 벡터 파일을 저장할 디렉터리를 먼저 생성합시다. 그리고 워드 \n",
    "벡터를 다루는데 유용한 gensim 패키지를 설치합시다.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5326ab3d-02ef-45f9-a8a0-5fb44717417c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3976133325.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m$ mkdir -p sentiment_classification/data\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 이미, 오늘 첫 스텝에서 설치되었으니,\n",
    "# 필요할 때만 Local terminal에서 아래 명령어를 입력해 주세요.\n",
    "$ mkdir -p sentiment_classification/data\n",
    "$ pip install gensim==4.3.2\n",
    "$ pip install scipy==1.12.0 numpy==1.26.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9f3c329-f196-431b-b5ff-9b40d178f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.embedding\n",
    "weights = embedding_layer.weight.detach().cpu().numpy()\n",
    "\n",
    "print(weights.shape)  # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d32c3cf2-5e9f-4e12-b5d6-8629031dac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다.\n",
    "word2vec_file_path = os.path.join(os.getenv('HOME') + '/word2vec.txt')\n",
    "\n",
    "with open(word2vec_file_path, 'w') as f:\n",
    "    f.write('{} {}\\n'.format(vocab_size - 4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "    # 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다.\n",
    "    vectors = model.embedding.weight.detach().cpu().numpy()\n",
    "    for i in range(4, vocab_size):\n",
    "        f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, vectors[i, :]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f697d23-7a4a-4259-90a6-abbb15e33b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.39048597, -0.32171926, -0.49570125,  0.5987515 , -0.82346684,\n",
       "       -0.50739485, -0.7251118 , -0.77163714, -0.14054525,  0.34299818,\n",
       "       -1.1977164 , -0.38771814, -0.58220243, -1.4523695 , -1.3591638 ,\n",
       "       -1.6058068 ], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gensim에서 제공하는 패키지를 이용해, 위에 남긴 임베딩 파라미터를 읽어서 word vector로 활용할 수 있습니다.\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e17b52-ab6a-460b-86c5-67c26b5c2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "위와 같이 얻은 워드 벡터를 가지고 재미있는 실험을 해볼 수 있습니다. \n",
    "워드 벡터가 의미 벡터 공간상에 유의미하게 학습되었는지 확인하는 방법 중에, \n",
    "단어를 하나 주고 그와 가장 유사한 단어와 그 유사도를 확인하는 방법이 있습니다. \n",
    "gensim을 사용하면 아래와 같이 해볼 수 있습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f022b3e3-c432-4d78-a72d-06ca9760b39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('remark', 0.8547155261039734),\n",
       " ('wins', 0.8032256364822388),\n",
       " ('native', 0.8018304705619812),\n",
       " ('underlying', 0.7979157567024231),\n",
       " ('victor', 0.7724127173423767),\n",
       " ('carpenter', 0.7408649325370789),\n",
       " ('producers', 0.7386540174484253),\n",
       " ('undeniably', 0.7164281010627747),\n",
       " ('natural', 0.7117794156074524),\n",
       " ('whacked', 0.7052521109580994)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd7869-a3f1-48a6-be12-affab3a73979",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "어떻습니까? love라는 단어와 유사한 다른 단어를 그리 잘 찾았다고 느껴지지는 않습니다.\n",
    "감성 분류 태스크를 잠깐 학습한 것만으로 워드 벡터가 유의미하게 학습되기는 \n",
    "어려운 것 같습니다. 우리가 다룬 정도의 훈련 데이터로는 워드 벡터를 정교하게 학습시키기\n",
    "어렵습니다.\n",
    "\n",
    "그래서 이번에는 구글에서 제공하는 Word2Vec이라는 사전학습된(Pretrained) 워드\n",
    "임베딩 모델을 가져다 활용해 보겠습니다. Word2Vec은 무려 1억 개의 단어로 구성된 \n",
    "Google News dataset을 바탕으로 학습되었습니다. 총 300만 개의 단어를 각각 300차원의\n",
    "벡터로 표현한 것입니다. Word2Vec이 학습되는 원리에 대해서는 차후 깊이 있게 다루게 될 \n",
    "것입니다. 하지만 그렇게 해서 학습된 Word2Vec이라는 것도 실은 방금 우리가 파일에 써본 \n",
    "Embedding Layer와 원리는 동일합니다.\n",
    "\n",
    "임베딩의 개념에 대해 아주 잘 정리된 책 한국어 임베딩의 서론에서 왜 사전학습된 임베딩을 \n",
    "활용하는 것이 유리한지 설명해 주고 있습니다. 바로 전이학습 때문입니다. 관련 내용을\n",
    "읽어본 후 질문에 답해 봅시다.\n",
    "\n",
    "한국어 임베딩 서문\n",
    "https://ratsgo.github.io/natural%20language%20processing/2019/09/12/embedding/\n",
    "\n",
    "그러면 본격적으로 Google의 Word2Vec 모델을 가져와 적용해 봅시다.\n",
    "\n",
    "이 링크를 클릭하면 무려 1.5GB 이상의 파일을 다운받게 됩니다. 다운받은 후에는 \n",
    "다음과 같이 진행해 봅시다.\n",
    "https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g\n",
    "\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a38e567e-f250-4547-b340-1f2b2c0ef2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat '/home/jovyan/Downloads/GoogleNews-vectors-negative300.bin.gz': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "mv ~/Downloads/GoogleNews-vectors-negative300.bin.gz ~/work/sentiment_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ddf9df21-dd24-407e-8f35-32806f58da06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = data_dir + 'GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a6b58-2eeb-4bcb-9b84-c74ce0334950",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "300dim의 벡터로 이루어진 300만 개의 단어입니다. 이 단어 사전을 메모리에 모두 로딩하면 \n",
    "아주 높은 확률로 여러분의 실습환경에 메모리 에러가 날 것입니다. \n",
    "그래서 KeyedVectors.load_word2vec_format 메서드로 워드 벡터를 로딩할 때 가장 많이\n",
    "사용되는 상위 100만 개만 limt으로 조건을 주어 로딩했습니다.\n",
    "\n",
    "메모리가 충분하다면 limt=None으로 하시면 300만 개를 모두 로딩합니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99b15ee5-562f-4ff2-86d4-076e387382a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13fc0aa5-d538-42b8-964b-9fdd8de8da3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n어떻습니까? Word2Vec에서 제공하는 워드 임베딩 벡터들끼리는 의미적 유사도가 \\n가까운 것이 서로 가깝게 제대로 학습된 것을 확인할 수 있습니다. \\n이제 우리는 이전 스텝에서 학습했던 모델의 임베딩 레이어를 Word2Vec의 것으로 교체하여\\n다시 학습시켜 볼 것입니다.\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "어떻습니까? Word2Vec에서 제공하는 워드 임베딩 벡터들끼리는 의미적 유사도가 \n",
    "가까운 것이 서로 가깝게 제대로 학습된 것을 확인할 수 있습니다. \n",
    "이제 우리는 이전 스텝에서 학습했던 모델의 임베딩 레이어를 Word2Vec의 것으로 교체하여\n",
    "다시 학습시켜 볼 것입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40c635a4-5a8d-4c5f-884d-29ac31ae460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "797f2d5e-a372-44a4-ab16-3e23de2090e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentModel(\n",
      "  (embedding): Embedding(10000, 300)\n",
      "  (conv1): Conv1d(300, 16, kernel_size=(7,), stride=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(16, 16, kernel_size=(7,), stride=(1,))\n",
      "  (global_max_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc1): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, vocab_size, word_vector_dim, embedding_matrix, maxlen):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, word_vector_dim)    # 카피한 임베딩을 여기서 활용\n",
    "        # self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight = nn.Parameter(\n",
    "        embedding_matrix.detach().clone().float()\n",
    "        )\n",
    "        self.embedding.weight.requires_grad = True\n",
    "        self.conv1 = nn.Conv1d(in_channels=word_vector_dim, out_channels=16, kernel_size=7)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=7)\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Linear(16, 8)\n",
    "        self.fc2 = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.global_max_pool(x).squeeze(2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수\n",
    "\n",
    "embedding_matrix = torch.randn(vocab_size, word_vector_dim)\n",
    "\n",
    "model = SentimentModel(vocab_size, word_vector_dim, embedding_matrix, maxlen)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71fd3002-7b3d-437d-acdf-6dba65ca6cc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# partial_x_train_tensor = torch.tensor(partial_x_train, dtype=torch.long)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# partial_y_train_tensor = torch.tensor(partial_y_train, dtype=torch.float)\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# x_val_tensor = torch.tensor(x_val, dtype=torch.long)\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# y_val_tensor = torch.tensor(y_val, dtype=torch.float)\u001b[39;00m\n\u001b[32m     12\u001b[39m partial_x_train_tensor = partial_x_train.detach().clone().long()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m partial_y_train_tensor = \u001b[43mpartial_y_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m().clone().float()\n\u001b[32m     15\u001b[39m x_val_tensor = x_val.detach().clone().long()\n\u001b[32m     16\u001b[39m y_val_tensor = y_val.detach().clone().float()\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "# partial_x_train_tensor = torch.tensor(partial_x_train, dtype=torch.long)\n",
    "# partial_y_train_tensor = torch.tensor(partial_y_train, dtype=torch.float)\n",
    "\n",
    "# x_val_tensor = torch.tensor(x_val, dtype=torch.long)\n",
    "# y_val_tensor = torch.tensor(y_val, dtype=torch.float)\n",
    "partial_x_train_tensor = partial_x_train.detach().clone().long()\n",
    "partial_y_train_tensor = partial_y_train.detach().clone().float()\n",
    "\n",
    "x_val_tensor = x_val.detach().clone().long()\n",
    "y_val_tensor = y_val.detach().clone().float()\n",
    "\n",
    "train_dataset = TensorDataset(partial_x_train_tensor, partial_y_train_tensor)\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "# 학습의 진행\n",
    "epochs = 20    # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다.\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        predicted = (outputs.squeeze() > 0.5).float()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accs.append(correct / total)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs.squeeze(), labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            predicted = (outputs.squeeze() > 0.5).float()\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accs.append(val_correct / val_total)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "          f\"Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accs[-1]:.4f} - \"\n",
    "          f\"Validation Loss: {val_losses[-1]:.4f}, Validation Accuracy: {val_accs[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb4850-9750-42a8-8b91-3708a15c4552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.squeeze(), labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        predicted = (outputs.squeeze() > 0.5).float()\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "print(f\"Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {test_correct / test_total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7cd06-be9a-4d93-b985-7dc37c3d6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "어떻습니까? Word2Vec을 정상적으로 잘 활용하면 그렇지 않은 경우보다 \n",
    "5% 이상의 성능 향상이 발생합니다. 적절한 모델 구성, 하이퍼파라미터를 고려하여 \n",
    "감정 분석 모델의 성능을 최대한으로 끌어올려 봅시다.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
